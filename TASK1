import pandas as pd
import numpy as np
from sklearn import datasets

# Load Iris Dataset
iris = datasets.load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target

# Display the original dataset
print("Original Dataset:")
print(df.head())
# Introduce some NaN values for demonstration
df.loc[5:10, 'sepal length (cm)'] = np.nan  # Introducing missing values

# Fill missing values with the mean of the column
df['sepal length (cm)'] = df['sepal length (cm)'].fillna(df['sepal length (cm)'].mean())

# Display after handling missing values
print("\nAfter Handling Missing Values:")
print(df.head(15))
from sklearn.preprocessing import LabelEncoder

# Encode categorical 'species' column
label_encoder = LabelEncoder()
df['species'] = label_encoder.fit_transform(df['species'])

# Display after encoding
print("\nAfter Encoding 'species' Column:")
print(df.head())
from sklearn.preprocessing import StandardScaler

# Standardize the features (excluding the target 'species')
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df.drop(columns='species'))

# Create a new DataFrame with scaled features
scaled_df = pd.DataFrame(scaled_features, columns=df.columns[:-1])

# Add the target variable (species) back to the scaled DataFrame
scaled_df['species'] = df['species']

# Display after scaling
print("\nAfter Feature Scaling:")
print(scaled_df.head())
from sklearn.model_selection import train_test_split

# Split the data into features (X) and target (y)
X = scaled_df.drop(columns='species')  # Features
y = scaled_df['species']  # Target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the train-test split
print("\nTraining Features (X_train):")
print(X_train.head())

print("\nTesting Features (X_test):")
print(X_test.head())
